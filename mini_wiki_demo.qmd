---
title: "Mini Wiki-QA ğŸ¤–"
format: html
---

This is a **small demo app** built with [Gradio](https://gradio.app) and deployed on [Hugging Face Spaces](https://huggingface.co/spaces).  
It answers simple questions based on a small **given context** â€” like a mini open-domain QA bot.

---

## ğŸ§  Project Summary

This demo is part of my learning path toward **Retrieval-Augmented Generation (RAG)** systems.

In a full RAG chatbot:
1. The user's query is first **embedded** into a vector space.
2. Relevant documents are **retrieved** from a vector database (e.g., Chroma).
3. A **language model (LLM)** generates an answer using the retrieved context.

Here, Iâ€™m focusing on **Step 3** â€” using a Hugging Face LLM API (`flan-t5-small`) to generate responses based on a short context.

---

## ğŸ§© How It Works

1. A fixed context is defined:

    `Python is a programming language created by Guido van Rossum. It emphasizes readability and is widely used in data science, web development, and automation.`

2. The user enters a question.
3. The app sends this to the Hugging Face model via the Inference API.
4. The model generates a response.

---

## ğŸš€ Try It Out

<iframe src="https://huggingface.co/spaces/ranjithnrjk/Sample_mini_project_demo"
        width="100%" height="600px" style="border:none;">
</iframe>

<!-- <div style="text-align:center">
  <a href="https://huggingface.co/spaces/ranjithnrjk/Sample_mini_project_demo"
     target="_blank">Open Demo on Hugging Face ğŸš€</a>
</div> -->

If youâ€™re viewing this locally and the demo doesnâ€™t load,  
you can open it directly here ğŸ‘‰  
[Launch on Hugging Face Spaces](https://huggingface.co/spaces/ranjithnrjk/Sample_mini_project_demo)

---

## ğŸ› ï¸ Tech Stack

- **Frontend/UI:** Gradio  
- **Model API:** Hugging Face Inference API  
- **Hosting:** Hugging Face Spaces  
- **Documentation Site:** Quarto + GitHub Pages

---

## ğŸ’¡ Next Steps

- Replace static context with dynamic document retrieval using **Chroma** or **FAISS**.  
- Integrate a larger model (e.g., `mistral-7b` or `gemma-2b`).  
- Add RAG pipeline â†’ full **contextual chatbot** experience.

---

## ğŸ“š Learnings

This project helped me understand:
- Using Hugging Face APIs for lightweight inference  
- Creating shareable ML demos without custom web dev  
- Embedding such demos in a personal portfolio using **Quarto**

---

*Built with â¤ï¸ by Ranjith Â· Powered by Hugging Face, Quarto, and GitHub Pages*