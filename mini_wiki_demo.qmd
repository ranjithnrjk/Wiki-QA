---
title: "Mini Wiki-QA 🤖"
format: html
---

This is a **small demo app** built with [Gradio](https://gradio.app) and deployed on [Hugging Face Spaces](https://huggingface.co/spaces).  
It answers simple questions based on a small **given context** — like a mini open-domain QA bot.

---

## 🧠 Project Summary

This demo is part of my learning path toward **Retrieval-Augmented Generation (RAG)** systems.

In a full RAG chatbot:
1. The user's query is first **embedded** into a vector space.
2. Relevant documents are **retrieved** from a vector database (e.g., Chroma).
3. A **language model (LLM)** generates an answer using the retrieved context.

Here, I’m focusing on **Step 3** — using a Hugging Face LLM API (`flan-t5-small`) to generate responses based on a short context.

---

## 🧩 How It Works

1. A fixed context is defined:

    `Python is a programming language created by Guido van Rossum. It emphasizes readability and is widely used in data science, web development, and automation.`

2. The user enters a question.
3. The app sends this to the Hugging Face model via the Inference API.
4. The model generates a response.

---

## 🚀 Try It Out

<iframe src="https://huggingface.co/spaces/ranjithnrjk/Sample_mini_project_demo"
        width="100%" height="600px" style="border:none;">
</iframe>

<!-- <div style="text-align:center">
  <a href="https://huggingface.co/spaces/ranjithnrjk/Sample_mini_project_demo"
     target="_blank">Open Demo on Hugging Face 🚀</a>
</div> -->

If you’re viewing this locally and the demo doesn’t load,  
you can open it directly here 👉  
[Launch on Hugging Face Spaces](https://huggingface.co/spaces/ranjithnrjk/Sample_mini_project_demo)

---

## 🛠️ Tech Stack

- **Frontend/UI:** Gradio  
- **Model API:** Hugging Face Inference API  
- **Hosting:** Hugging Face Spaces  
- **Documentation Site:** Quarto + GitHub Pages

---

## 💡 Next Steps

- Replace static context with dynamic document retrieval using **Chroma** or **FAISS**.  
- Integrate a larger model (e.g., `mistral-7b` or `gemma-2b`).  
- Add RAG pipeline → full **contextual chatbot** experience.

---

## 📚 Learnings

This project helped me understand:
- Using Hugging Face APIs for lightweight inference  
- Creating shareable ML demos without custom web dev  
- Embedding such demos in a personal portfolio using **Quarto**

---

*Built with ❤️ by Ranjith · Powered by Hugging Face, Quarto, and GitHub Pages*