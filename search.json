[
  {
    "objectID": "mini_wiki_demo.html",
    "href": "mini_wiki_demo.html",
    "title": "Mini Wiki-QA 🤖",
    "section": "",
    "text": "This is a small demo app built with Gradio and deployed on Hugging Face Spaces.\nIt answers simple questions based on a small given context — like a mini open-domain QA bot."
  },
  {
    "objectID": "mini_wiki_demo.html#project-summary",
    "href": "mini_wiki_demo.html#project-summary",
    "title": "Mini Wiki-QA 🤖",
    "section": "🧠 Project Summary",
    "text": "🧠 Project Summary\nThis demo is part of my learning path toward Retrieval-Augmented Generation (RAG) systems.\nIn a full RAG chatbot: 1. The user’s query is first embedded into a vector space. 2. Relevant documents are retrieved from a vector database (e.g., Chroma). 3. A language model (LLM) generates an answer using the retrieved context.\nHere, I’m focusing on Step 3 — using a Hugging Face LLM API (flan-t5-small) to generate responses based on a short context."
  },
  {
    "objectID": "mini_wiki_demo.html#how-it-works",
    "href": "mini_wiki_demo.html#how-it-works",
    "title": "Mini Wiki-QA 🤖",
    "section": "🧩 How It Works",
    "text": "🧩 How It Works\n\nA fixed context is defined:\nPython is a programming language created by Guido van Rossum. It emphasizes readability and is widely used in data science, web development, and automation.\nThe user enters a question.\nThe app sends this to the Hugging Face model via the Inference API.\nThe model generates a response."
  },
  {
    "objectID": "mini_wiki_demo.html#try-it-out",
    "href": "mini_wiki_demo.html#try-it-out",
    "title": "Mini Wiki-QA 🤖",
    "section": "🚀 Try It Out",
    "text": "🚀 Try It Out\n\n\nOpen Demo on Hugging Face 🚀\n\nIf you’re viewing this locally and the demo doesn’t load,\nyou can open it directly here 👉\nLaunch on Hugging Face Spaces"
  },
  {
    "objectID": "mini_wiki_demo.html#tech-stack",
    "href": "mini_wiki_demo.html#tech-stack",
    "title": "Mini Wiki-QA 🤖",
    "section": "🛠️ Tech Stack",
    "text": "🛠️ Tech Stack\n\nFrontend/UI: Gradio\n\nModel API: Hugging Face Inference API\n\nHosting: Hugging Face Spaces\n\nDocumentation Site: Quarto + GitHub Pages"
  },
  {
    "objectID": "mini_wiki_demo.html#next-steps",
    "href": "mini_wiki_demo.html#next-steps",
    "title": "Mini Wiki-QA 🤖",
    "section": "💡 Next Steps",
    "text": "💡 Next Steps\n\nReplace static context with dynamic document retrieval using Chroma or FAISS.\n\nIntegrate a larger model (e.g., mistral-7b or gemma-2b).\n\nAdd RAG pipeline → full contextual chatbot experience."
  },
  {
    "objectID": "mini_wiki_demo.html#learnings",
    "href": "mini_wiki_demo.html#learnings",
    "title": "Mini Wiki-QA 🤖",
    "section": "📚 Learnings",
    "text": "📚 Learnings\nThis project helped me understand: - Using Hugging Face APIs for lightweight inference\n- Creating shareable ML demos without custom web dev\n- Embedding such demos in a personal portfolio using Quarto\n\nBuilt with ❤️ by Ranjith · Powered by Hugging Face, Quarto, and GitHub Pages"
  }
]